# JobCheck â€“ Detecting Fake Job Posts Using NLP

A comprehensive NLP-based system for detecting fraudulent job postings using machine learning and web technologies.

## ðŸ“‹ Project Overview

This project is divided into 4 main modules, each focusing on a specific aspect of the fake job detection system:

- **Module 1**: Data Collection & Preprocessing
- **Module 2**: Fake Job Classification Model
- **Module 3**: Web Interface & Prediction API
- **Module 4**: Dashboard & Admin Panel

## ðŸ—‚ï¸ Project Structure

```
Fake_Job_Detection_NLP/
â”œâ”€â”€ module1_data_preprocessing/    # Data collection and preprocessing
â”œâ”€â”€ module2_model_training/        # ML model development and evaluation
â”œâ”€â”€ module3_web_interface/         # Flask/FastAPI backend and frontend
â”œâ”€â”€ module4_dashboard/             # Admin panel and analytics dashboard
â”œâ”€â”€ data/                          # Dataset storage
â”œâ”€â”€ models/                        # Saved ML models and vectorizers
â”œâ”€â”€ logs/                          # Application logs
â”œâ”€â”€ config/                        # Configuration files
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ README.md                      # This file
```

## ðŸš€ Quick Start

### Prerequisites

- Python 3.8+
- pip or conda

### Installation

1. Clone the repository:
```bash
git clone https://github.com/9brahiim/Fake_Job_Posting_Detection-.git
cd Fake_Job_Detection_NLP
```

2. Create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Download the dataset from [Kaggle](https://www.kaggle.com/datasets/shivamb/real-or-fake-fake-jobposting-prediction) and place it in the `data/` directory.

## ðŸ“š Module Descriptions

### Module 1: Data Collection & Preprocessing
**Location**: `module1_data_preprocessing/`

- Load and inspect the Fake Job Postings dataset
- Merge textual fields (Job Description + Requirements + Benefits)
- Clean and normalize text (lowercase, remove HTML, punctuation, stopwords)
- Extract features using TF-IDF vectorization
- Output: Cleaned and vectorized data ready for ML models

### Module 2: Fake Job Classification Model
**Location**: `module2_model_training/`

- Train baseline models: Logistic Regression and Random Forest
- Evaluate models using Accuracy, Precision, Recall, F1-Score
- Compare model performance
- Save best model and TF-IDF vectorizer as `.pkl` files
- Target: Accuracy > 90%

### Module 3: Web Interface & Prediction API
**Location**: `module3_web_interface/`

- Flask/FastAPI backend for prediction API
- Web form for user input
- Real-time prediction with confidence scores
- Preprocessing pipeline matching training phase

### Module 4: Dashboard & Admin Panel
**Location**: `module4_dashboard/`

- Secure admin authentication (JWT)
- Prediction analytics and visualization
- Export functionality (CSV/PDF)
- Model retraining capabilities
- Database integration for prediction logs

## ðŸ—“ï¸ Week-Wise Execution Strategy

- **Weeks 1â€“2**: Data & NLP (Module 1)
- **Weeks 3â€“4**: Model Development (Module 2)
- **Weeks 5â€“6**: Web Application (Module 3)
- **Weeks 7â€“8**: Admin & Dashboard (Module 4)

## ðŸ‘¥ Contributing

Each module is designed to be worked on independently. Please follow these guidelines:

1. Create a branch for your module: `git checkout -b module1-data-preprocessing`
2. Work on your assigned module
3. Test your code thoroughly
4. Submit a pull request with a clear description

## ðŸ“ Dataset

The project uses the **Fake Job Postings** dataset from Kaggle:
- [Dataset Link](https://www.kaggle.com/datasets/shivamb/real-or-fake-fake-jobposting-prediction)

Key attributes:
- Job Title
- Company Profile
- Job Description
- Requirements
- Benefits
- Fraudulent label (0 â€“ Real, 1 â€“ Fake)

## ðŸ› ï¸ Technology Stack

- **NLP**: NLTK, spaCy, scikit-learn
- **ML**: scikit-learn, TensorFlow/PyTorch (optional)
- **Backend**: Flask/FastAPI
- **Frontend**: HTML, CSS, Bootstrap (React optional)
- **Database**: SQLite/MySQL/PostgreSQL
- **Visualization**: Chart.js

## ðŸ“Š Expected Results

- **Accuracy**: > 90%
- **F1-Score**: Strong balanced performance
- **Real-time Prediction**: < 2 seconds response time

## ðŸ“„ License

This project is open source and available under the MIT License.

## ðŸ‘¤ Author

9brahiim

## ðŸ™ Acknowledgments

- Kaggle for providing the dataset
- Open source community for tools and libraries
